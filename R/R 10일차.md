# R 10일차

## 1. 의사 결정 트리(Decision Tree)

- 의사 결정 트리(Decision Tree)

  - 나무(Tree) 구조 형태로 분류결과를 도출
  - 입력변수 중 가장 영향력 있는 변수를 기준으로 이진분류하여 분류 결과를 나무 구조 형태로 시각화
  - 비교적 모델 생성이 쉽고, 단순, 명료하여 현업에서 많이 사용되는 지도학습 모델
  - 의사결정규칙을 도표화 하여 분류와 예측을 수행하는 분석방법
  - party 패키지 ctree()
  - rpart 패키지 rpart()

  

  - party 패키지 ctree()  분류 결과 해석
  - 첫번째 번호는 반응변수(종속변수)에 대해서 설명변수(독립변수)가 영향을 미치는 중요 변수의 척도를 나타내는 수치로서 수치가 작을 수록 영향을 미치는 정도가 높고, 순서는 분기되는 순서를 의미한다.
  - 두번째는 의사결정 트리의 노드명 (노드 번호 뒤에 * 기호가 오면 해당 노드가 마지막 노드를 의미)
     노드명 뒤에 해당 변수의 임계값이 조건식으로 온다
  - 세번째는 노드의 분기 기준(criterion)이 되는 수치
  - 네번째는 반응변수(종속변수)의 통계량(statistic)이 표시된다. 

```R
install.packages("party")
library(party)
library(datasets)
str(airquality) # 관측 154개, 변수 6개

formula <- Temp ~ Solar.R+Wind+Ozone
air_ctree <- ctree(formula, data=airquality)
air_ctree
plot(air_ctree)
```

![1569199275517](assets/1569199275517.png)

```R
#온도에 가장 큰 영향을 미치는 첫번째 영향변수는 Ozone
# 두번째 영향변수는 Wind
# 오존량 37이하이면서 바람의 양이 15.5이상이면 평균온도는 63정도에 해당
#바람의 양이 15.5이하인 경우 평균 온도는 70이상으로 나타남
#태양광은 온도에 영향을 미치지 않는 것으로 분석됨
```



## 2. iris 데이터 셋으로 분류 분석 수행

```R
set.seed(1234) # 시드값을 적용하면 랜덤 값이 동일하게 생성
idx <- sample(1:nrow(iris), nrow(iris)*0.7)
train <- iris[idx, ] # 학습 데이터
test <- iris[-idx, ] # -는 제외, 검정 데이터

# 종속변수는 Species, 독립변수는 나머지
formula <- Species ~ Sepal.Length + Sepal.Width + Petal.Length + Petal.Width #(~는 영향을 주는 요소)

#분류모델 생성
iris_ctree <- ctree(formula, data=train)
iris_ctree
plot(iris_ctree, type="simple")
```

![1569199797839](assets/1569199797839.png)

```R
# 꽃종 분류에 가장 중요한 독립변수는? Petal.Length, Petal.Width

# 분류모델 평가 - 예측치 생성, 혼돈 매트릭스 생성

pred <- predict(iris_ctree, test)
table(pred, test$Species) # 예측값이 행, Species가 열

#분류 정확도 : ( 16 + 15 + 12) / nrow(test)
> ( 16 + 15 + 12) / nrow(test)
[1] 0.9555556 / 95.56%

> nrow(test)
[1] 45
```

